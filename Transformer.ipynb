{"cells":[{"cell_type":"markdown","source":["baseline code.\n","https://dacon.io/edu/338"],"metadata":{"id":"uCdDroBjwlIX"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25149,"status":"ok","timestamp":1733803943449,"user":{"displayName":"김민서","userId":"06054877758271253489"},"user_tz":-540},"id":"BNV1dZZLqNZm","outputId":"71b0e218-5e3e-4e55-bd24-2f81c5f3c618"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mh5JzwtVqQav"},"outputs":[],"source":["!unzip -qq \"/content/drive/MyDrive/DS/open.zip\""]},{"cell_type":"markdown","source":["# Library"],"metadata":{"id":"HOpkGfomyhfw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1SvyhYaapgwo"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from tqdm.notebook import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from types import SimpleNamespace\n","from sklearn.preprocessing import MinMaxScaler\n","import os"]},{"cell_type":"markdown","source":["# Hyperparameter Setting"],"metadata":{"id":"hAQGrvMKykSb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxMK5sM7poSk"},"outputs":[],"source":["config = {\n","    \"learning_rate\": 1e-5,\n","    \"epoch\": 100,\n","    \"batch_size\": 64,\n","    \"hidden_size\": 64,\n","    \"num_layers\": 2,\n","    \"output_size\": 3,\n","    \"num_heads\": 1,\n","    \"dropout\": 0.3,\n","    \"step_size\": 10,\n","    \"gamma\": 0.8\n","}\n","\n","CFG = SimpleNamespace(**config)\n","\n","item_list = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추', '배추', '양파', '대파']"]},{"cell_type":"markdown","source":["# Define Function for Feature Engineering"],"metadata":{"id":"wdmee2RdyoGa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fI7EZxgEiops"},"outputs":[],"source":["import re\n","from datetime import datetime\n","\n","def parse_custom_date(date_str):\n","    # 접두사 'T-' 제거\n","    if date_str.startswith('T-'):\n","        date_str = date_str.lstrip('T-')\n","\n","    # 정규식으로 날짜를 파싱\n","    match = re.match(r\"(\\d{4})(\\d{2})(상순|중순|하순)\", date_str)\n","    if match:\n","        year, month, part = match.groups()\n","        # 상순, 중순, 하순을 각각 1일, 11일, 21일로 매핑\n","        day = {\"상순\": \"01\", \"중순\": \"11\", \"하순\": \"21\"}[part]\n","        # 날짜 생성\n","        return datetime.strptime(f\"{year}-{month}-{day}\", \"%Y-%m-%d\")\n","    else:\n","        return None\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H32S4lD_9Y7o"},"outputs":[],"source":["def process_data(raw_file, 산지공판장_file, 전국도매_file, 품목명, scaler=None):\n","    raw_data = pd.read_csv(raw_file)\n","    산지공판장 = pd.read_csv(산지공판장_file)\n","    전국도매 = pd.read_csv(전국도매_file)\n","\n","    # 타겟 및 메타데이터 필터 조건 정의\n","    conditions = {\n","    '감자': {\n","        'target': lambda df: (df['품종명'] == '감자 수미') & (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n","        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['감자'], '품종명': ['수미'], '등급명': ['상']},\n","        '도매': {'시장명': ['*전국도매시장'], '품목명': ['감자'], '품종명': ['수미']}\n","    },\n","    '건고추': {\n","        'target': lambda df: (df['품종명'] == '화건') & (df['거래단위'] == '30 kg') & (df['등급'] == '상품'),\n","        '공판장': None,\n","        '도매': None\n","    },\n","    '깐마늘(국산)': {\n","        'target': lambda df: (df['거래단위'] == '20 kg') & (df['등급'] == '상품'),\n","        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['마늘'], '품종명': ['깐마늘'], '등급명': ['상']},\n","        '도매': {'시장명': ['*전국도매시장'], '품목명': ['마늘'], '품종명': ['깐마늘']}\n","    },\n","    '대파': {\n","        'target': lambda df: (df['품종명'] == '대파(일반)') & (df['거래단위'] == '1키로단') & (df['등급'] == '상'),\n","        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['대파'], '품종명': ['대파(일반)'], '등급명': ['상']},\n","        '도매': {'시장명': ['*전국도매시장'], '품목명': ['대파'], '품종명': ['대파(일반)']}\n","    },\n","    '무': {\n","        'target': lambda df: (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n","        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['무'], '품종명': ['기타무'], '등급명': ['상']},\n","        '도매': {'시장명': ['*전국도매시장'], '품목명': ['무'], '품종명': ['무']}\n","    },\n","    '배추': {\n","        'target': lambda df: (df['거래단위'] == '10키로망대') & (df['등급'] == '상'),\n","        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배추'], '품종명': ['쌈배추'], '등급명': ['상']},\n","        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배추'], '품종명': ['배추']}\n","    },\n","    '사과': {\n","        'target': lambda df: (df['품종명'].isin(['홍로', '후지'])) & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n","        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['사과'], '품종명': ['후지'], '등급명': ['상']},\n","        '도매': {'시장명': ['*전국도매시장'], '품목명': ['사과'], '품종명': ['후지']}\n","    },\n","    '상추': {\n","        'target': lambda df: (df['품종명'] == '청') & (df['거래단위'] == '100 g') & (df['등급'] == '상품'),\n","        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['상추'], '품종명': ['청상추'], '등급명': ['상']},\n","        '도매': {'시장명': ['*전국도매시장'], '품목명': ['상추'], '품종명': ['청상추']}\n","    },\n","    '양파': {\n","        'target': lambda df: (df['품종명'] == '양파') & (df['거래단위'] == '1키로') & (df['등급'] == '상'),\n","        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['양파'], '품종명': ['기타양파'], '등급명': ['상']},\n","        '도매': {'시장명': ['*전국도매시장'], '품목명': ['양파'], '품종명': ['양파(일반)']}\n","    },\n","    '배': {\n","        'target': lambda df: (df['품종명'] == '신고') & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n","        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배'], '품종명': ['신고'], '등급명': ['상']},\n","        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배'], '품종명': ['신고']}\n","    }\n","    }\n","\n","    # 타겟 데이터 필터링\n","    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n","    target_mask = conditions[품목명]['target'](raw_품목)\n","    filtered_data = raw_품목[target_mask]\n","\n","    # 다른 품종에 대한 파생변수 생성\n","    other_data = raw_품목[~target_mask]\n","    unique_combinations = other_data[['품종명', '거래단위', '등급']].drop_duplicates()\n","    for _, row in unique_combinations.iterrows():\n","        품종명, 거래단위, 등급 = row['품종명'], row['거래단위'], row['등급']\n","        mask = (other_data['품종명'] == 품종명) & (other_data['거래단위'] == 거래단위) & (other_data['등급'] == 등급)\n","        temp_df = other_data[mask]\n","        for col in ['평년 평균가격(원)', '평균가격(원)']:\n","            new_col_name = f'{품종명}_{거래단위}_{등급}_{col}'\n","            filtered_data = filtered_data.merge(temp_df[['시점', col]], on='시점', how='left', suffixes=('', f'_{new_col_name}'))\n","            filtered_data.rename(columns={f'{col}_{new_col_name}': new_col_name}, inplace=True)\n","\n","\n","    # 공판장 데이터 처리\n","    if conditions[품목명]['공판장']:\n","        filtered_공판장 = 산지공판장\n","        for key, value in conditions[품목명]['공판장'].items():\n","            filtered_공판장 = filtered_공판장[filtered_공판장[key].isin(value)]\n","\n","        filtered_공판장 = filtered_공판장.add_prefix('공판장_').rename(columns={'공판장_시점': '시점'})\n","        filtered_data = filtered_data.merge(filtered_공판장, on='시점', how='left')\n","\n","    # 도매 데이터 처리\n","    if conditions[품목명]['도매']:\n","        filtered_도매 = 전국도매\n","        for key, value in conditions[품목명]['도매'].items():\n","            filtered_도매 = filtered_도매[filtered_도매[key].isin(value)]\n","\n","        filtered_도매 = filtered_도매.add_prefix('도매_').rename(columns={'도매_시점': '시점'})\n","        filtered_data = filtered_data.merge(filtered_도매, on='시점', how='left')\n","\n","    ### 날짜변환 ###\n","    filtered_data['시점'] = filtered_data['시점'].apply(parse_custom_date)\n","    ##############\n","\n","    # 수치형 컬럼 처리\n","    numeric_columns = filtered_data.select_dtypes(include=[np.number]).columns\n","    filtered_data = filtered_data[['시점'] + list(numeric_columns)]\n","    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n","\n","    ### 결측치 처리: 먼저 선형 보간법을 적용하고, ###\n","    filtered_data[numeric_columns] = filtered_data[numeric_columns].interpolate(method='linear', limit_direction='both')\n","    ### 선형보간법 이후에도 여전히 NaN이 남아있는 경우, NaN을 평균으로 대체 ###\n","    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(filtered_data[numeric_columns].mean())\n","    ##################\n","\n","    ### 이상치 처리: IQR 방법 ###\n","#    for col in numeric_columns:\n","#        Q1 = filtered_data[col].quantile(0.25)\n","#        Q3 = filtered_data[col].quantile(0.75)\n","#        IQR = Q3 - Q1\n","#        lower_bound = Q1 - 1.5 * IQR\n","#        upper_bound = Q3 + 1.5 * IQR\n","#        filtered_data = filtered_data[(filtered_data[col] >= lower_bound) & (filtered_data[col] <= upper_bound)]\n","    #####################\n","\n","#####mentori님의 이상치 처리 부분 참고 ######\n","    for col in numeric_columns:\n","        for i in range(1, len(filtered_data)):\n","            if filtered_data.loc[i, col] == 0:  # 0인 값을 이상치로 간주\n","                filtered_data.loc[i, col] = filtered_data.loc[i - 1, col]  # 이전 값으로 대체\n","\n","    # 평균가격 값이 0인 것이 일정 수준 이하라면 그 칼럼을 제거한다.\n","    drop_columns = []\n","    for col in filtered_data.columns:\n","        zero_cols = len(filtered_data[filtered_data[col]==0])\n","        if zero_cols/len(filtered_data) > 0.5:\n","            drop_columns.append(col)\n","###################################################\n","\n","    # 정규화 적용\n","    if scaler is None:\n","        scaler = MinMaxScaler()\n","        filtered_data[numeric_columns] = scaler.fit_transform(filtered_data[numeric_columns])\n","    else:\n","        filtered_data[numeric_columns] = scaler.transform(filtered_data[numeric_columns])\n","\n","    return filtered_data, scaler\n"]},{"cell_type":"markdown","source":["기존 베이스라인 코드에다가 아래 사항들을 추가함.   \n","    \n","(1) 이상치 처리: IQR을 사용해 이상치를 식별하고 제거. ((각 수치형 컬럼에 대해 1.5 * IQR 범위를 벗어난 값을 제거.  \n","  => 가끔가다 0인 경우에서 에러가 남. 이상치처리부분을 극단적인 이상치만 평균값으로 대체하는 방식으로 전환하였음.  \n","  =>이상치가 0인 경우는 이전값으로 대체했더니 loss가 줄어들었음\n","  \n","(2) 시간 변수 추가: 시점에서 연도, 월, 분기, 계절 정보를 파생 변수로 생성.   \n","\n","(3) 결측치 처리: 선형 보간법을 사용해 연속적인 시간 데이터를 고려한 결측치 보완.\n"],"metadata":{"id":"6mwOQ-58y6ps"}},{"cell_type":"markdown","source":["# Define Custom Dataset Class"],"metadata":{"id":"uM6vnQbdzTlq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Upyu8YjK9a8j"},"outputs":[],"source":["# Define custom dataset class\n","class AgriculturePriceDataset(Dataset):\n","    def __init__(self, dataframe, window_size=9, prediction_length=3, is_test=False):\n","        self.data = dataframe\n","        self.window_size = window_size\n","        self.prediction_length = prediction_length\n","        self.is_test = is_test\n","\n","        self.price_column = [col for col in self.data.columns if '평균가격(원)' in col and len(col.split('_')) == 1][0]\n","        self.numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()\n","\n","        self.sequences = []\n","        if not self.is_test:\n","            for i in range(len(self.data) - self.window_size - self.prediction_length + 1):\n","                x = self.data[self.numeric_columns].iloc[i:i+self.window_size].values\n","                y = self.data[self.price_column].iloc[i+self.window_size:i+self.window_size+self.prediction_length].values\n","                self.sequences.append((x, y))\n","        else:\n","            self.sequences = [self.data[self.numeric_columns].values]\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, idx):\n","        if not self.is_test:\n","            x, y = self.sequences[idx]\n","            return torch.FloatTensor(x), torch.FloatTensor(y)\n","        else:\n","            return torch.FloatTensor(self.sequences[idx])"]},{"cell_type":"markdown","source":["# Define Model"],"metadata":{"id":"T-dlGQg_LuaG"}},{"cell_type":"markdown","source":["### Transformer\n","##### All_day님의 코드를 참고하였음.\n","https://dacon.io/competitions/official/236381/codeshare/11637?page=1&dtype=recent"],"metadata":{"id":"AXtoyF_JLypr"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPPgQd4U9dNx"},"outputs":[],"source":["class Time2Vec(nn.Module):\n","    def __init__(self, input_dim):\n","        super(Time2Vec, self).__init__()\n","        self.linear = nn.Linear(input_dim, 1)\n","        self.periodic = nn.Linear(input_dim, input_dim-1)\n","\n","    def forward(self, x):\n","        linear_out = self.linear(x)\n","        periodic_out = torch.sin(self.periodic(x))\n","        return torch.cat([linear_out, periodic_out], dim=-1)\n","\n","# Define simplified Transformer Encoder Block\n","class TransformerBlock(nn.Module):\n","    def __init__(self, input_dim, num_heads, dropout):\n","        super(TransformerBlock, self).__init__()\n","        self.attention = nn.MultiheadAttention(input_dim, num_heads, dropout=dropout)\n","        self.norm1 = nn.LayerNorm(input_dim)\n","        self.ff = nn.Sequential(\n","            nn.Linear(input_dim, input_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        attended, _ = self.attention(x, x, x)\n","        x = x + attended\n","        x = self.norm1(x)\n","\n","        feedforward = self.ff(x)\n","        x = x + feedforward\n","        return x\n","\n","# Define simplified Time Series Transformer\n","class TimeSeriesTransformer(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_heads, output_size, dropout):\n","        super(TimeSeriesTransformer, self).__init__()\n","        self.time2vec = Time2Vec(input_size)\n","        self.embedding = nn.Linear(input_size, hidden_size)\n","        self.position_encoding = self.generate_position_encoding(hidden_size, 10)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.transformer_blocks = nn.ModuleList([\n","            TransformerBlock(hidden_size, num_heads, dropout)\n","            for _ in range(num_layers)\n","        ])\n","\n","        self.output_layer = nn.Sequential(\n","            nn.Linear(hidden_size, hidden_size // 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_size // 2, output_size)\n","        )\n","\n","    def generate_position_encoding(self, hidden_size, max_len):\n","        pe = torch.zeros(max_len, hidden_size)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, hidden_size, 2).float() * (-np.log(10000.0) / hidden_size))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        return pe.unsqueeze(0)\n","\n","    def forward(self, x):\n","        b, s, f = x.shape\n","        x = self.time2vec(x)\n","        x = self.embedding(x)\n","\n","        # Apply position encoding\n","        x = x + self.position_encoding[:, :s, :].to(x.device)\n","        x = self.dropout(x)\n","\n","        for transformer in self.transformer_blocks:\n","            x = transformer(x)\n","\n","        x = x.mean(dim=1)  # Global average pooling over sequence\n","        return self.output_layer(x)\n"]},{"cell_type":"markdown","source":["(1) 기울기 클리핑.\n","\n","(2) BatchNorm 제거.\n","\n","(3) FeedForward 네트워크 축소.\n","\n","(4) 하이퍼파라미터 변경(레이어 축소, 학습률 감소, 드롭아웃 등)"],"metadata":{"id":"K5jo4XpVzYol"}},{"cell_type":"markdown","source":["# Training Functions"],"metadata":{"id":"d9kpr7d-0LLY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yssl_tSikIIS"},"outputs":[],"source":["# Training function with mixed precision training\n","def train_model(model, train_loader, criterion, optimizer, scheduler, scaler, device):\n","    model.train()\n","    total_loss = 0\n","    for batch_x, batch_y in train_loader:\n","        batch_x, batch_y = batch_x.to(device), batch_y.to(device)  # 데이터를 GPU로 이동\n","        optimizer.zero_grad()\n","\n","        with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n","            outputs = model(batch_x)\n","            loss = criterion(outputs, batch_y)\n","\n","        scaler.scale(loss).backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        scheduler.step()\n","        total_loss += loss.item()\n","\n","    return total_loss / len(train_loader)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wUzQ5dJ1kLPK"},"outputs":[],"source":["# Evaluation function\n","def evaluate_model(model, test_loader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    with torch.no_grad():\n","        for batch_x, batch_y in test_loader:\n","            batch_x, batch_y = batch_x.to(device), batch_y.to(device)  # 데이터를 GPU로 이동\n","            outputs = model(batch_x)\n","            loss = criterion(outputs, batch_y)\n","            total_loss += loss.item()\n","    return total_loss / len(test_loader)"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","mpl.rcParams['font.family'] = 'AppleGothic'\n","mpl.rcParams['axes.unicode_minus'] = False\n","\n","품목명 = \"무\"\n","\n","# 데이터를 전처리\n","train_data, scaler = process_data(\n","    \"./train/train.csv\",\n","    \"./train/meta/TRAIN_산지공판장_2018-2021.csv\",\n","    \"./train/meta/TRAIN_전국도매_2018-2021.csv\",\n","    품목명\n",")\n","\n","# 열 이름 확인\n","print(train_data.columns)\n","\n","# 데이터셋 개요\n","print(\"\\n--- 데이터셋 개요 ---\")\n","print(train_data.info())\n","\n","# 컬럼별 결측치 수\n","print(\"\\n--- 컬럼별 결측치 수 ---\")\n","missing_values = train_data.isnull().sum()\n","print(missing_values[missing_values > 0])\n","\n","# 주요 통계값\n","print(\"\\n--- 주요 통계값 ---\")\n","print(train_data.describe())\n","\n","# 타겟 변수(평균가격(원)) 분포 시각화\n","plt.figure(figsize=(10, 5))\n","plt.hist(train_data['평균가격(원)'], bins=30, color='skyblue', edgecolor='black')\n","plt.title(f\"{품목명} 평균가격(원) 분포\")\n","plt.xlabel('평균가격(원)')\n","plt.ylabel('빈도수')\n","plt.show()\n","\n","# 컬럼별 상관관계\n","correlation_matrix = train_data.corr()\n","print(\"\\n--- 컬럼별 상관관계 ---\")\n","print(correlation_matrix)\n","plt.show()\n"],"metadata":{"id":"MQn4Mk0z1sQk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(2, 1, figsize=(15, 6))\n","\n","for col in train_data.columns:\n","    if \"평균가격\" in col and \"평년\" not in col and col != \"평균가격(원)\":\n","\n","        # 극단적인 이상치만 평균값으로 대체\n","        for i in range(1, len(train_data)):\n","            if train_data.loc[i, col] == 0:\n","                train_data.loc[i, col] = train_data.loc[i - 1, col]\n","\n","        axs[0].plot(train_data[\"시점\"], train_data[col], label=col)\n","axs[1].plot(train_data[\"시점\"], train_data['평균가격(원)'], color=\"blue\")"],"metadata":{"id":"UeZhpmm41u9G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loss Functions"],"metadata":{"id":"7gJDUBj90R_Z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gtlSeSxilGc8"},"outputs":[],"source":["class NMAELoss(nn.Module):\n","    def __init__(self, eps=1e-6):\n","        super(NMAELoss, self).__init__()\n","        self.eps = eps  # 작은 값 추가\n","\n","    def forward(self, y_pred, y_true):\n","        mae = torch.abs(y_pred - y_true).mean()\n","        # y_true의 평균을 기준으로 정규화, eps를 추가하여 안정성 확보\n","        nmae = mae / (torch.mean(torch.abs(y_true)) + self.eps)\n","        return nmae\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fMyjZfAglc8j"},"outputs":[],"source":["import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"]},{"cell_type":"markdown","source":["# Train Models and Generate Predictions"],"metadata":{"id":"gfoahHuW0Xpk"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xf0PQGtt9e31","executionInfo":{"status":"ok","timestamp":1733813908643,"user_tz":-540,"elapsed":231398,"user":{"displayName":"김민서","userId":"06054877758271253489"}},"outputId":"f82e9821-a78e-4298-c715-7d8de1a7a58b"},"outputs":[{"output_type":"stream","name":"stderr","text":["품목별 전처리 및 모델 학습 -> 건고추:   0%|          | 0/10 [00:00<?, ?it/s]<ipython-input-82-f76e61ff9cd5>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-78-66bf2b439d23>:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 0.9397\n","Epoch 2/100, Train Loss: 0.7125\n","Epoch 3/100, Train Loss: 0.6235\n","Epoch 4/100, Train Loss: 0.5840\n","Epoch 5/100, Train Loss: 0.5371\n","Epoch 6/100, Train Loss: 0.5636\n","Epoch 7/100, Train Loss: 0.5706\n","Epoch 8/100, Train Loss: 0.5141\n","Epoch 9/100, Train Loss: 0.5991\n","Epoch 10/100, Train Loss: 0.5646\n","Epoch 11/100, Train Loss: 0.5926\n","Epoch 12/100, Train Loss: 0.5779\n","Epoch 13/100, Train Loss: 0.5183\n","Epoch 14/100, Train Loss: 0.5086\n","Epoch 15/100, Train Loss: 0.5401\n","Epoch 16/100, Train Loss: 0.4646\n","Epoch 17/100, Train Loss: 0.5336\n","Epoch 18/100, Train Loss: 0.5500\n","Epoch 19/100, Train Loss: 0.4762\n","Epoch 20/100, Train Loss: 0.5066\n","Epoch 21/100, Train Loss: 0.4724\n","Epoch 22/100, Train Loss: 0.5017\n","Epoch 23/100, Train Loss: 0.5264\n","Epoch 24/100, Train Loss: 0.4903\n","Epoch 25/100, Train Loss: 0.4637\n","Epoch 26/100, Train Loss: 0.5015\n","Epoch 27/100, Train Loss: 0.4271\n","Epoch 28/100, Train Loss: 0.5262\n","Epoch 29/100, Train Loss: 0.5010\n","Epoch 30/100, Train Loss: 0.4961\n","Epoch 31/100, Train Loss: 0.4542\n","Epoch 32/100, Train Loss: 0.4746\n","Epoch 33/100, Train Loss: 0.4744\n","Epoch 34/100, Train Loss: 0.4597\n","Epoch 35/100, Train Loss: 0.4639\n","Epoch 36/100, Train Loss: 0.4866\n","Epoch 37/100, Train Loss: 0.4766\n","Epoch 38/100, Train Loss: 0.4553\n","Epoch 39/100, Train Loss: 0.4637\n","Epoch 40/100, Train Loss: 0.4576\n","Epoch 41/100, Train Loss: 0.4285\n","Epoch 42/100, Train Loss: 0.4499\n","Epoch 43/100, Train Loss: 0.4457\n","Epoch 44/100, Train Loss: 0.4452\n","Epoch 45/100, Train Loss: 0.4641\n","Epoch 46/100, Train Loss: 0.4750\n","Epoch 47/100, Train Loss: 0.4553\n","Epoch 48/100, Train Loss: 0.4524\n","Epoch 49/100, Train Loss: 0.4243\n","Epoch 50/100, Train Loss: 0.4729\n","Epoch 51/100, Train Loss: 0.4610\n","Epoch 52/100, Train Loss: 0.4487\n","Epoch 53/100, Train Loss: 0.4499\n","Epoch 54/100, Train Loss: 0.4315\n","Epoch 55/100, Train Loss: 0.4455\n","Epoch 56/100, Train Loss: 0.4579\n","Epoch 57/100, Train Loss: 0.4775\n","Epoch 58/100, Train Loss: 0.4284\n","Epoch 59/100, Train Loss: 0.4510\n","Epoch 60/100, Train Loss: 0.4404\n","Epoch 61/100, Train Loss: 0.4326\n","Epoch 62/100, Train Loss: 0.4148\n","Epoch 63/100, Train Loss: 0.4070\n","Epoch 64/100, Train Loss: 0.4405\n","Epoch 65/100, Train Loss: 0.4382\n","Epoch 66/100, Train Loss: 0.4552\n","Epoch 67/100, Train Loss: 0.4457\n","Epoch 68/100, Train Loss: 0.4604\n","Epoch 69/100, Train Loss: 0.4141\n","Epoch 70/100, Train Loss: 0.4624\n","Epoch 71/100, Train Loss: 0.4148\n","Epoch 72/100, Train Loss: 0.4008\n","Epoch 73/100, Train Loss: 0.4487\n","Epoch 74/100, Train Loss: 0.4710\n","Epoch 75/100, Train Loss: 0.4090\n","Epoch 76/100, Train Loss: 0.4281\n","Epoch 77/100, Train Loss: 0.4294\n","Epoch 78/100, Train Loss: 0.4280\n","Epoch 79/100, Train Loss: 0.4476\n","Epoch 80/100, Train Loss: 0.4595\n","Epoch 81/100, Train Loss: 0.4356\n","Epoch 82/100, Train Loss: 0.4417\n","Epoch 83/100, Train Loss: 0.4332\n","Epoch 84/100, Train Loss: 0.4467\n","Epoch 85/100, Train Loss: 0.4174\n","Epoch 86/100, Train Loss: 0.4562\n","Epoch 87/100, Train Loss: 0.4380\n","Epoch 88/100, Train Loss: 0.4161\n","Epoch 89/100, Train Loss: 0.4613\n","Epoch 90/100, Train Loss: 0.4396\n","Epoch 91/100, Train Loss: 0.4584\n","Epoch 92/100, Train Loss: 0.4102\n","Epoch 93/100, Train Loss: 0.4239\n","Epoch 94/100, Train Loss: 0.4158\n","Epoch 95/100, Train Loss: 0.4074\n","Epoch 96/100, Train Loss: 0.4305\n","Epoch 97/100, Train Loss: 0.4472\n","Epoch 98/100, Train Loss: 0.4564\n","Epoch 99/100, Train Loss: 0.4233\n","Epoch 100/100, Train Loss: 0.4009\n","Best Validation Loss for 건고추: 0.4686\n"]},{"output_type":"stream","name":"stderr","text":["\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:03,  6.46it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:03,  6.46it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:00<00:03,  6.12it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:00<00:03,  6.12it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:00<00:03,  6.36it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:00<00:03,  6.36it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:00<00:03,  6.52it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:00<00:03,  6.52it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:00<00:03,  6.52it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:00<00:03,  6.52it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:00<00:02,  6.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:01<00:02,  6.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:01<00:02,  6.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:01<00:02,  6.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:01<00:02,  6.15it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:01<00:02,  6.15it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:01<00:02,  6.00it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:01<00:02,  6.00it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:01<00:02,  6.28it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:01<00:02,  6.28it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:01<00:02,  6.43it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:01<00:02,  6.43it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:01<00:02,  6.33it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:02<00:02,  6.33it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:02<00:01,  6.41it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:02<00:01,  6.41it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:02<00:01,  6.47it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:02<00:01,  6.47it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:02<00:01,  6.09it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:02<00:01,  6.09it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:02<00:01,  6.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:02<00:01,  6.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:02<00:01,  6.21it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:02<00:01,  6.21it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:02<00:01,  6.05it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:03<00:01,  6.05it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:03<00:00,  6.16it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:03<00:00,  6.16it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:03<00:00,  6.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:03<00:00,  6.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:03<00:00,  6.08it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:03<00:00,  6.08it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:03<00:00,  6.13it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:03<00:00,  6.13it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:03<00:00,  6.01it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:03<00:00,  6.01it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:03<00:00,  5.91it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:04<00:00,  5.91it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중: 100%|██████████| 25/25 [00:04<00:00,  6.09it/s, 상태=정상]\u001b[A\n","품목별 전처리 및 모델 학습 -> 사과:  20%|██        | 2/10 [00:07<00:58,  7.34s/it]  <ipython-input-82-f76e61ff9cd5>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-78-66bf2b439d23>:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 1.3239\n","Epoch 2/100, Train Loss: 0.9256\n","Epoch 3/100, Train Loss: 0.7119\n","Epoch 4/100, Train Loss: 0.6755\n","Epoch 5/100, Train Loss: 0.6714\n","Epoch 6/100, Train Loss: 0.6568\n","Epoch 7/100, Train Loss: 0.6232\n","Epoch 8/100, Train Loss: 0.6078\n","Epoch 9/100, Train Loss: 0.6267\n","Epoch 10/100, Train Loss: 0.6227\n","Epoch 11/100, Train Loss: 0.5854\n","Epoch 12/100, Train Loss: 0.5865\n","Epoch 13/100, Train Loss: 0.5830\n","Epoch 14/100, Train Loss: 0.6015\n","Epoch 15/100, Train Loss: 0.5586\n","Epoch 16/100, Train Loss: 0.5857\n","Epoch 17/100, Train Loss: 0.5533\n","Epoch 18/100, Train Loss: 0.5641\n","Epoch 19/100, Train Loss: 0.5831\n","Epoch 20/100, Train Loss: 0.5658\n","Epoch 21/100, Train Loss: 0.5411\n","Epoch 22/100, Train Loss: 0.5598\n","Epoch 23/100, Train Loss: 0.5538\n","Epoch 24/100, Train Loss: 0.5637\n","Epoch 25/100, Train Loss: 0.5339\n","Epoch 26/100, Train Loss: 0.5144\n","Epoch 27/100, Train Loss: 0.5498\n","Epoch 28/100, Train Loss: 0.5499\n","Epoch 29/100, Train Loss: 0.5400\n","Epoch 30/100, Train Loss: 0.5818\n","Epoch 31/100, Train Loss: 0.5415\n","Epoch 32/100, Train Loss: 0.5129\n","Epoch 33/100, Train Loss: 0.5552\n","Epoch 34/100, Train Loss: 0.5380\n","Epoch 35/100, Train Loss: 0.5317\n","Epoch 36/100, Train Loss: 0.5559\n","Epoch 37/100, Train Loss: 0.5443\n","Epoch 38/100, Train Loss: 0.5400\n","Epoch 39/100, Train Loss: 0.5275\n","Epoch 40/100, Train Loss: 0.5300\n","Epoch 41/100, Train Loss: 0.5258\n","Epoch 42/100, Train Loss: 0.5538\n","Epoch 43/100, Train Loss: 0.5319\n","Epoch 44/100, Train Loss: 0.4982\n","Epoch 45/100, Train Loss: 0.5005\n","Epoch 46/100, Train Loss: 0.4964\n","Epoch 47/100, Train Loss: 0.5353\n","Epoch 48/100, Train Loss: 0.5222\n","Epoch 49/100, Train Loss: 0.5088\n","Epoch 50/100, Train Loss: 0.5189\n","Epoch 51/100, Train Loss: 0.5201\n","Epoch 52/100, Train Loss: 0.5544\n","Epoch 53/100, Train Loss: 0.5176\n","Epoch 54/100, Train Loss: 0.5320\n","Epoch 55/100, Train Loss: 0.5304\n","Epoch 56/100, Train Loss: 0.5230\n","Epoch 57/100, Train Loss: 0.5279\n","Epoch 58/100, Train Loss: 0.5112\n","Epoch 59/100, Train Loss: 0.5384\n","Epoch 60/100, Train Loss: 0.5194\n","Epoch 61/100, Train Loss: 0.5399\n","Epoch 62/100, Train Loss: 0.4952\n","Epoch 63/100, Train Loss: 0.5278\n","Epoch 64/100, Train Loss: 0.5342\n","Epoch 65/100, Train Loss: 0.5101\n","Epoch 66/100, Train Loss: 0.5412\n","Epoch 67/100, Train Loss: 0.5248\n","Epoch 68/100, Train Loss: 0.4992\n","Epoch 69/100, Train Loss: 0.5486\n","Epoch 70/100, Train Loss: 0.5304\n","Epoch 71/100, Train Loss: 0.5112\n","Epoch 72/100, Train Loss: 0.5190\n","Epoch 73/100, Train Loss: 0.5308\n","Epoch 74/100, Train Loss: 0.5010\n","Epoch 75/100, Train Loss: 0.5555\n","Epoch 76/100, Train Loss: 0.5178\n","Epoch 77/100, Train Loss: 0.5327\n","Epoch 78/100, Train Loss: 0.5106\n","Epoch 79/100, Train Loss: 0.5119\n","Epoch 80/100, Train Loss: 0.4977\n","Epoch 81/100, Train Loss: 0.5296\n","Epoch 82/100, Train Loss: 0.5166\n","Epoch 83/100, Train Loss: 0.5034\n","Epoch 84/100, Train Loss: 0.5288\n","Epoch 85/100, Train Loss: 0.5210\n","Epoch 86/100, Train Loss: 0.5304\n","Epoch 87/100, Train Loss: 0.5097\n","Epoch 88/100, Train Loss: 0.4938\n","Epoch 89/100, Train Loss: 0.4925\n","Epoch 90/100, Train Loss: 0.4974\n","Epoch 91/100, Train Loss: 0.5083\n","Epoch 92/100, Train Loss: 0.5102\n","Epoch 93/100, Train Loss: 0.5126\n","Epoch 94/100, Train Loss: 0.5138\n","Epoch 95/100, Train Loss: 0.5405\n","Epoch 96/100, Train Loss: 0.5228\n","Epoch 97/100, Train Loss: 0.5290\n","Epoch 98/100, Train Loss: 0.5279\n","Epoch 99/100, Train Loss: 0.4946\n","Epoch 100/100, Train Loss: 0.5198\n","Best Validation Loss for 사과: 0.4413\n"]},{"output_type":"stream","name":"stderr","text":["\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:07,  3.10it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:07,  3.10it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:00<00:07,  2.99it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:00<00:07,  2.99it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:00<00:07,  3.11it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:01<00:07,  3.11it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:01<00:06,  3.21it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:01<00:06,  3.21it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:01<00:06,  3.25it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:01<00:06,  3.25it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:01<00:06,  3.16it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:02<00:06,  3.16it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:02<00:05,  3.14it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:02<00:05,  3.14it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:02<00:05,  3.22it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:02<00:05,  3.22it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:02<00:04,  3.60it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:02<00:04,  3.60it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:02<00:03,  3.95it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:03<00:03,  3.95it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:03<00:03,  4.15it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:03<00:03,  4.15it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:03<00:02,  4.43it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:03<00:02,  4.43it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:03<00:02,  4.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:03<00:02,  4.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:03<00:02,  4.60it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:03<00:02,  4.60it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:03<00:02,  4.41it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:04<00:02,  4.41it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:04<00:02,  4.32it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:04<00:02,  4.32it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:04<00:01,  4.39it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:04<00:01,  4.39it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:04<00:01,  4.45it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:04<00:01,  4.45it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:04<00:01,  4.60it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:05<00:01,  4.60it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:05<00:01,  4.58it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:05<00:01,  4.58it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:05<00:00,  4.79it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:05<00:00,  4.79it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:05<00:00,  4.87it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:05<00:00,  4.87it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:05<00:00,  4.91it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:05<00:00,  4.91it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:05<00:00,  4.83it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:06<00:00,  4.83it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중: 100%|██████████| 25/25 [00:06<00:00,  4.64it/s, 상태=정상]\u001b[A\n","품목별 전처리 및 모델 학습 -> 감자:  40%|████      | 4/10 [00:17<00:34,  5.75s/it]<ipython-input-75-c60575a9ccd0>:102: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n","<ipython-input-75-c60575a9ccd0>:105: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  filtered_data[numeric_columns] = filtered_data[numeric_columns].interpolate(method='linear', limit_direction='both')\n","<ipython-input-82-f76e61ff9cd5>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-78-66bf2b439d23>:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 1.1954\n","Epoch 2/100, Train Loss: 0.8616\n","Epoch 3/100, Train Loss: 0.6489\n","Epoch 4/100, Train Loss: 0.6372\n","Epoch 5/100, Train Loss: 0.5873\n","Epoch 6/100, Train Loss: 0.6587\n","Epoch 7/100, Train Loss: 0.6112\n","Epoch 8/100, Train Loss: 0.5509\n","Epoch 9/100, Train Loss: 0.5494\n","Epoch 10/100, Train Loss: 0.5609\n","Epoch 11/100, Train Loss: 0.5386\n","Epoch 12/100, Train Loss: 0.5445\n","Epoch 13/100, Train Loss: 0.5362\n","Epoch 14/100, Train Loss: 0.5295\n","Epoch 15/100, Train Loss: 0.5491\n","Epoch 16/100, Train Loss: 0.5468\n","Epoch 17/100, Train Loss: 0.5338\n","Epoch 18/100, Train Loss: 0.5328\n","Epoch 19/100, Train Loss: 0.5341\n","Epoch 20/100, Train Loss: 0.5150\n","Epoch 21/100, Train Loss: 0.4994\n","Epoch 22/100, Train Loss: 0.5165\n","Epoch 23/100, Train Loss: 0.5143\n","Epoch 24/100, Train Loss: 0.4751\n","Epoch 25/100, Train Loss: 0.4663\n","Epoch 26/100, Train Loss: 0.4743\n","Epoch 27/100, Train Loss: 0.4722\n","Epoch 28/100, Train Loss: 0.4603\n","Epoch 29/100, Train Loss: 0.4455\n","Epoch 30/100, Train Loss: 0.4779\n","Epoch 31/100, Train Loss: 0.4389\n","Epoch 32/100, Train Loss: 0.4230\n","Epoch 33/100, Train Loss: 0.3914\n","Epoch 34/100, Train Loss: 0.4189\n","Epoch 35/100, Train Loss: 0.4435\n","Epoch 36/100, Train Loss: 0.4512\n","Epoch 37/100, Train Loss: 0.4225\n","Epoch 38/100, Train Loss: 0.4021\n","Epoch 39/100, Train Loss: 0.4237\n","Epoch 40/100, Train Loss: 0.4468\n","Epoch 41/100, Train Loss: 0.4312\n","Epoch 42/100, Train Loss: 0.4485\n","Epoch 43/100, Train Loss: 0.4002\n","Epoch 44/100, Train Loss: 0.3886\n","Epoch 45/100, Train Loss: 0.4025\n","Epoch 46/100, Train Loss: 0.4255\n","Epoch 47/100, Train Loss: 0.4399\n","Epoch 48/100, Train Loss: 0.3934\n","Epoch 49/100, Train Loss: 0.3931\n","Epoch 50/100, Train Loss: 0.4371\n","Epoch 51/100, Train Loss: 0.4343\n","Epoch 52/100, Train Loss: 0.4023\n","Epoch 53/100, Train Loss: 0.4210\n","Epoch 54/100, Train Loss: 0.4423\n","Epoch 55/100, Train Loss: 0.4099\n","Epoch 56/100, Train Loss: 0.4016\n","Epoch 57/100, Train Loss: 0.3941\n","Epoch 58/100, Train Loss: 0.3613\n","Epoch 59/100, Train Loss: 0.3864\n","Epoch 60/100, Train Loss: 0.3671\n","Epoch 61/100, Train Loss: 0.3968\n","Epoch 62/100, Train Loss: 0.3610\n","Epoch 63/100, Train Loss: 0.3951\n","Epoch 64/100, Train Loss: 0.3789\n","Epoch 65/100, Train Loss: 0.3704\n","Epoch 66/100, Train Loss: 0.3515\n","Epoch 67/100, Train Loss: 0.3832\n","Epoch 68/100, Train Loss: 0.3825\n","Epoch 69/100, Train Loss: 0.3707\n","Epoch 70/100, Train Loss: 0.3754\n","Epoch 71/100, Train Loss: 0.3758\n","Epoch 72/100, Train Loss: 0.3837\n","Epoch 73/100, Train Loss: 0.3964\n","Epoch 74/100, Train Loss: 0.3775\n","Epoch 75/100, Train Loss: 0.3896\n","Epoch 76/100, Train Loss: 0.3526\n","Epoch 77/100, Train Loss: 0.3633\n","Epoch 78/100, Train Loss: 0.3889\n","Epoch 79/100, Train Loss: 0.3480\n","Epoch 80/100, Train Loss: 0.3879\n","Epoch 81/100, Train Loss: 0.3682\n","Epoch 82/100, Train Loss: 0.4060\n","Epoch 83/100, Train Loss: 0.3944\n","Epoch 84/100, Train Loss: 0.3570\n","Epoch 85/100, Train Loss: 0.3686\n","Epoch 86/100, Train Loss: 0.3596\n","Epoch 87/100, Train Loss: 0.3891\n","Epoch 88/100, Train Loss: 0.3773\n","Epoch 89/100, Train Loss: 0.3998\n","Epoch 90/100, Train Loss: 0.3584\n","Epoch 91/100, Train Loss: 0.3826\n","Epoch 92/100, Train Loss: 0.3467\n","Epoch 93/100, Train Loss: 0.3573\n","Epoch 94/100, Train Loss: 0.3875\n","Epoch 95/100, Train Loss: 0.3414\n","Epoch 96/100, Train Loss: 0.3826\n","Epoch 97/100, Train Loss: 0.3931\n","Epoch 98/100, Train Loss: 0.3558\n","Epoch 99/100, Train Loss: 0.3485\n","Epoch 100/100, Train Loss: 0.3546\n","Best Validation Loss for 감자: 0.3579\n"]},{"output_type":"stream","name":"stderr","text":["\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:21,  1.14it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:01<00:21,  1.14it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:01<00:21,  1.08it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:02<00:21,  1.08it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:02<00:19,  1.14it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:03<00:19,  1.14it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:03<00:19,  1.10it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:04<00:19,  1.10it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:04<00:17,  1.17it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:04<00:17,  1.17it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:05<00:14,  1.29it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:05<00:14,  1.29it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:05<00:13,  1.38it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:06<00:13,  1.38it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:06<00:11,  1.43it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:06<00:11,  1.43it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:06<00:10,  1.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:07<00:10,  1.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:07<00:09,  1.53it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:08<00:09,  1.53it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:08<00:09,  1.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:08<00:09,  1.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:08<00:08,  1.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:09<00:08,  1.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:09<00:07,  1.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:09<00:07,  1.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:09<00:06,  1.61it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:10<00:06,  1.61it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:10<00:06,  1.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:11<00:06,  1.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:11<00:05,  1.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:11<00:05,  1.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:11<00:05,  1.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:12<00:05,  1.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:12<00:04,  1.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:13<00:04,  1.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:13<00:03,  1.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:13<00:03,  1.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:13<00:03,  1.62it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:14<00:03,  1.62it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:14<00:02,  1.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:15<00:02,  1.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:15<00:02,  1.34it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:16<00:02,  1.34it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:16<00:01,  1.25it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:17<00:01,  1.25it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:17<00:00,  1.17it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:18<00:00,  1.17it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중: 100%|██████████| 25/25 [00:18<00:00,  1.15it/s, 상태=정상]\u001b[A\n","품목별 전처리 및 모델 학습 -> 배:  50%|█████     | 5/10 [00:42<00:45,  9.17s/it]  <ipython-input-82-f76e61ff9cd5>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-78-66bf2b439d23>:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 1.3429\n","Epoch 2/100, Train Loss: 0.9408\n","Epoch 3/100, Train Loss: 0.6997\n","Epoch 4/100, Train Loss: 0.6732\n","Epoch 5/100, Train Loss: 0.5815\n","Epoch 6/100, Train Loss: 0.6099\n","Epoch 7/100, Train Loss: 0.5502\n","Epoch 8/100, Train Loss: 0.5330\n","Epoch 9/100, Train Loss: 0.5795\n","Epoch 10/100, Train Loss: 0.4961\n","Epoch 11/100, Train Loss: 0.5041\n","Epoch 12/100, Train Loss: 0.5000\n","Epoch 13/100, Train Loss: 0.5325\n","Epoch 14/100, Train Loss: 0.5020\n","Epoch 15/100, Train Loss: 0.5194\n","Epoch 16/100, Train Loss: 0.5171\n","Epoch 17/100, Train Loss: 0.5195\n","Epoch 18/100, Train Loss: 0.4788\n","Epoch 19/100, Train Loss: 0.5001\n","Epoch 20/100, Train Loss: 0.4629\n","Epoch 21/100, Train Loss: 0.4724\n","Epoch 22/100, Train Loss: 0.4879\n","Epoch 23/100, Train Loss: 0.4741\n","Epoch 24/100, Train Loss: 0.4853\n","Epoch 25/100, Train Loss: 0.4932\n","Epoch 26/100, Train Loss: 0.4464\n","Epoch 27/100, Train Loss: 0.4753\n","Epoch 28/100, Train Loss: 0.4732\n","Epoch 29/100, Train Loss: 0.4774\n","Epoch 30/100, Train Loss: 0.4276\n","Epoch 31/100, Train Loss: 0.4869\n","Epoch 32/100, Train Loss: 0.4662\n","Epoch 33/100, Train Loss: 0.4591\n","Epoch 34/100, Train Loss: 0.4312\n","Epoch 35/100, Train Loss: 0.4652\n","Epoch 36/100, Train Loss: 0.4430\n","Epoch 37/100, Train Loss: 0.4306\n","Epoch 38/100, Train Loss: 0.4434\n","Epoch 39/100, Train Loss: 0.4265\n","Epoch 40/100, Train Loss: 0.4134\n","Epoch 41/100, Train Loss: 0.4184\n","Epoch 42/100, Train Loss: 0.4256\n","Epoch 43/100, Train Loss: 0.4231\n","Epoch 44/100, Train Loss: 0.3982\n","Epoch 45/100, Train Loss: 0.4358\n","Epoch 46/100, Train Loss: 0.4000\n","Epoch 47/100, Train Loss: 0.4315\n","Epoch 48/100, Train Loss: 0.4411\n","Epoch 49/100, Train Loss: 0.3943\n","Epoch 50/100, Train Loss: 0.4062\n","Epoch 51/100, Train Loss: 0.3999\n","Epoch 52/100, Train Loss: 0.3754\n","Epoch 53/100, Train Loss: 0.3971\n","Epoch 54/100, Train Loss: 0.4171\n","Epoch 55/100, Train Loss: 0.4045\n","Epoch 56/100, Train Loss: 0.3951\n","Epoch 57/100, Train Loss: 0.3852\n","Epoch 58/100, Train Loss: 0.4038\n","Epoch 59/100, Train Loss: 0.4066\n","Epoch 60/100, Train Loss: 0.4058\n","Epoch 61/100, Train Loss: 0.3816\n","Epoch 62/100, Train Loss: 0.4119\n","Epoch 63/100, Train Loss: 0.4528\n","Epoch 64/100, Train Loss: 0.3944\n","Epoch 65/100, Train Loss: 0.4499\n","Epoch 66/100, Train Loss: 0.3929\n","Epoch 67/100, Train Loss: 0.4087\n","Epoch 68/100, Train Loss: 0.3953\n","Epoch 69/100, Train Loss: 0.3993\n","Epoch 70/100, Train Loss: 0.3776\n","Epoch 71/100, Train Loss: 0.3938\n","Epoch 72/100, Train Loss: 0.4100\n","Epoch 73/100, Train Loss: 0.4016\n","Epoch 74/100, Train Loss: 0.4030\n","Epoch 75/100, Train Loss: 0.4142\n","Epoch 76/100, Train Loss: 0.4066\n","Epoch 77/100, Train Loss: 0.4139\n","Epoch 78/100, Train Loss: 0.4057\n","Epoch 79/100, Train Loss: 0.3966\n","Epoch 80/100, Train Loss: 0.4016\n","Epoch 81/100, Train Loss: 0.3831\n","Epoch 82/100, Train Loss: 0.3996\n","Epoch 83/100, Train Loss: 0.3904\n","Epoch 84/100, Train Loss: 0.3750\n","Epoch 85/100, Train Loss: 0.4160\n","Epoch 86/100, Train Loss: 0.3815\n","Epoch 87/100, Train Loss: 0.3993\n","Epoch 88/100, Train Loss: 0.3764\n","Epoch 89/100, Train Loss: 0.3679\n","Epoch 90/100, Train Loss: 0.3816\n","Epoch 91/100, Train Loss: 0.4108\n","Epoch 92/100, Train Loss: 0.3899\n","Epoch 93/100, Train Loss: 0.3555\n","Epoch 94/100, Train Loss: 0.3636\n","Epoch 95/100, Train Loss: 0.3837\n","Epoch 96/100, Train Loss: 0.4061\n","Epoch 97/100, Train Loss: 0.3710\n","Epoch 98/100, Train Loss: 0.3708\n","Epoch 99/100, Train Loss: 0.3720\n","Epoch 100/100, Train Loss: 0.4088\n","Best Validation Loss for 배: 0.3807\n"]},{"output_type":"stream","name":"stderr","text":["\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:05,  4.73it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:05,  4.73it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:00<00:04,  4.76it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:00<00:04,  4.76it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:00<00:04,  5.16it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:00<00:04,  5.16it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:00<00:04,  5.19it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:00<00:04,  5.19it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:00<00:03,  5.30it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:01<00:03,  5.30it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:01<00:03,  5.37it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:01<00:03,  5.37it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:01<00:03,  4.94it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:01<00:03,  4.94it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:01<00:03,  4.87it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:01<00:03,  4.87it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:01<00:03,  4.98it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:01<00:03,  4.98it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:01<00:02,  5.14it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:02<00:02,  5.14it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:02<00:02,  5.30it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:02<00:02,  5.30it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:02<00:02,  5.26it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:02<00:02,  5.26it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:02<00:02,  5.12it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:02<00:02,  5.12it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:02<00:02,  5.22it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:02<00:02,  5.22it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:02<00:01,  5.15it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:03<00:01,  5.15it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:03<00:01,  5.11it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:03<00:01,  5.11it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:03<00:01,  4.89it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:03<00:01,  4.89it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:03<00:01,  4.80it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:03<00:01,  4.80it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:03<00:01,  4.94it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:03<00:01,  4.94it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:03<00:00,  5.13it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:04<00:00,  5.13it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:04<00:00,  5.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:04<00:00,  5.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:04<00:00,  4.96it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:04<00:00,  4.96it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:04<00:00,  5.03it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:04<00:00,  5.03it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:04<00:00,  4.85it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:04<00:00,  4.85it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중: 100%|██████████| 25/25 [00:04<00:00,  5.04it/s, 상태=정상]\u001b[A\n","품목별 전처리 및 모델 학습 -> 깐마늘(국산):  70%|███████   | 7/10 [00:51<00:27,  9.06s/it]<ipython-input-82-f76e61ff9cd5>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-78-66bf2b439d23>:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 147465.8516\n","Epoch 2/100, Train Loss: 137643.3906\n","Epoch 3/100, Train Loss: 161161.2969\n","Epoch 4/100, Train Loss: 147491.4922\n","Epoch 5/100, Train Loss: 154011.8594\n","Epoch 6/100, Train Loss: 142363.8750\n","Epoch 7/100, Train Loss: 142781.7891\n","Epoch 8/100, Train Loss: 149109.9922\n","Epoch 9/100, Train Loss: 153146.7734\n","Epoch 10/100, Train Loss: 145111.3672\n","Epoch 11/100, Train Loss: 99746.4141\n","Epoch 12/100, Train Loss: 78275.3867\n","Epoch 13/100, Train Loss: 55422.7227\n","Epoch 14/100, Train Loss: 43133.6777\n","Epoch 15/100, Train Loss: 39592.1211\n","Epoch 16/100, Train Loss: 37872.3730\n","Epoch 17/100, Train Loss: 33737.2168\n","Epoch 18/100, Train Loss: 30869.5098\n","Epoch 19/100, Train Loss: 30674.4346\n","Epoch 20/100, Train Loss: 28781.6338\n","Epoch 21/100, Train Loss: 26754.8545\n","Epoch 22/100, Train Loss: 26190.4766\n","Epoch 23/100, Train Loss: 24080.4756\n","Epoch 24/100, Train Loss: 25699.5078\n","Epoch 25/100, Train Loss: 26103.6836\n","Epoch 26/100, Train Loss: 22154.8340\n","Epoch 27/100, Train Loss: 23112.7773\n","Epoch 28/100, Train Loss: 22963.5293\n","Epoch 29/100, Train Loss: 24051.4131\n","Epoch 30/100, Train Loss: 20145.3379\n","Epoch 31/100, Train Loss: 21518.5576\n","Epoch 32/100, Train Loss: 22843.0254\n","Epoch 33/100, Train Loss: 19794.5439\n","Epoch 34/100, Train Loss: 20415.1172\n","Epoch 35/100, Train Loss: 21173.7197\n","Epoch 36/100, Train Loss: 19566.2725\n","Epoch 37/100, Train Loss: 20724.0264\n","Epoch 38/100, Train Loss: 19923.4111\n","Epoch 39/100, Train Loss: 19614.0742\n","Epoch 40/100, Train Loss: 19012.2061\n","Epoch 41/100, Train Loss: 19167.5859\n","Epoch 42/100, Train Loss: 19104.5098\n","Epoch 43/100, Train Loss: 18708.3076\n","Epoch 44/100, Train Loss: 16884.0029\n","Epoch 45/100, Train Loss: 18483.0723\n","Epoch 46/100, Train Loss: 17525.8389\n","Epoch 47/100, Train Loss: 18111.4229\n","Epoch 48/100, Train Loss: 18415.9092\n","Epoch 49/100, Train Loss: 18382.0664\n","Epoch 50/100, Train Loss: 17303.1436\n","Epoch 51/100, Train Loss: 17312.8066\n","Epoch 52/100, Train Loss: 15825.0654\n","Epoch 53/100, Train Loss: 17174.9668\n","Epoch 54/100, Train Loss: 16031.1748\n","Epoch 55/100, Train Loss: 16164.5576\n","Epoch 56/100, Train Loss: 16826.2480\n","Epoch 57/100, Train Loss: 15410.0171\n","Epoch 58/100, Train Loss: 16158.5874\n","Epoch 59/100, Train Loss: 17074.4346\n","Epoch 60/100, Train Loss: 15628.1104\n","Epoch 61/100, Train Loss: 15673.1772\n","Epoch 62/100, Train Loss: 16068.5083\n","Epoch 63/100, Train Loss: 15681.7676\n","Epoch 64/100, Train Loss: 15177.4727\n","Epoch 65/100, Train Loss: 15791.8516\n","Epoch 66/100, Train Loss: 15057.8535\n","Epoch 67/100, Train Loss: 14046.6865\n","Epoch 68/100, Train Loss: 15580.2500\n","Epoch 69/100, Train Loss: 14987.4419\n","Epoch 70/100, Train Loss: 16054.0415\n","Epoch 71/100, Train Loss: 15339.2930\n","Epoch 72/100, Train Loss: 15587.5459\n","Epoch 73/100, Train Loss: 14358.7119\n","Epoch 74/100, Train Loss: 14948.3198\n","Epoch 75/100, Train Loss: 16261.4263\n","Epoch 76/100, Train Loss: 15517.5171\n","Epoch 77/100, Train Loss: 14792.9761\n","Epoch 78/100, Train Loss: 14309.1011\n","Epoch 79/100, Train Loss: 14495.1802\n","Epoch 80/100, Train Loss: 14023.6597\n","Epoch 81/100, Train Loss: 13885.8433\n","Epoch 82/100, Train Loss: 15441.9580\n","Epoch 83/100, Train Loss: 14225.0947\n","Epoch 84/100, Train Loss: 14805.7446\n","Epoch 85/100, Train Loss: 14270.0386\n","Epoch 86/100, Train Loss: 14993.7378\n","Epoch 87/100, Train Loss: 14865.8931\n","Epoch 88/100, Train Loss: 14330.6504\n","Epoch 89/100, Train Loss: 14623.8408\n","Epoch 90/100, Train Loss: 14350.4019\n","Epoch 91/100, Train Loss: 14650.7861\n","Epoch 92/100, Train Loss: 14559.6187\n","Epoch 93/100, Train Loss: 14297.5908\n","Epoch 94/100, Train Loss: 15037.2554\n","Epoch 95/100, Train Loss: 15203.2144\n","Epoch 96/100, Train Loss: 13775.9697\n","Epoch 97/100, Train Loss: 14478.1299\n","Epoch 98/100, Train Loss: 14361.6836\n","Epoch 99/100, Train Loss: 13892.2671\n","Epoch 100/100, Train Loss: 14537.7476\n","Best Validation Loss for 깐마늘(국산): 6279.6055\n"]},{"output_type":"stream","name":"stderr","text":["\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:06,  3.46it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:06,  3.46it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:00<00:12,  1.88it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:01<00:12,  1.88it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:01<00:08,  2.45it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:01<00:08,  2.45it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:01<00:06,  3.18it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:01<00:06,  3.18it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:01<00:05,  3.75it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:01<00:05,  3.75it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:01<00:04,  4.25it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:01<00:04,  4.25it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:01<00:03,  4.62it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:02<00:03,  4.62it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:02<00:03,  4.80it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:02<00:03,  4.80it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:02<00:03,  5.17it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:02<00:03,  5.17it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:02<00:02,  5.43it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:02<00:02,  5.43it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:02<00:02,  5.53it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:02<00:02,  5.53it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:02<00:02,  5.70it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:02<00:02,  5.70it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:03<00:02,  5.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:03<00:02,  5.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:03<00:01,  5.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:03<00:01,  5.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:03<00:01,  5.64it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:03<00:01,  5.64it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:03<00:01,  5.65it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:03<00:01,  5.65it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:03<00:01,  5.62it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:03<00:01,  5.62it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:03<00:01,  5.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:04<00:01,  5.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:04<00:01,  5.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:04<00:01,  5.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:04<00:00,  5.44it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:04<00:00,  5.44it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:04<00:00,  5.47it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:04<00:00,  5.47it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:04<00:00,  5.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:04<00:00,  5.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:04<00:00,  5.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:04<00:00,  5.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:05<00:00,  5.45it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:05<00:00,  5.45it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중: 100%|██████████| 25/25 [00:05<00:00,  5.46it/s, 상태=정상]\u001b[A\n","품목별 전처리 및 모델 학습 -> 무:  80%|████████  | 8/10 [01:00<00:14,  7.18s/it]          <ipython-input-82-f76e61ff9cd5>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-78-66bf2b439d23>:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 159715.2891\n","Epoch 2/100, Train Loss: 174802.4297\n","Epoch 3/100, Train Loss: 154347.3594\n","Epoch 4/100, Train Loss: 165881.9453\n","Epoch 5/100, Train Loss: 166164.1953\n","Epoch 6/100, Train Loss: 163686.8047\n","Epoch 7/100, Train Loss: 165947.6562\n","Epoch 8/100, Train Loss: 153406.0234\n","Epoch 9/100, Train Loss: 169779.9844\n","Epoch 10/100, Train Loss: 160344.8516\n","Epoch 11/100, Train Loss: 178598.8047\n","Epoch 12/100, Train Loss: 105123.8516\n","Epoch 13/100, Train Loss: 84200.3750\n","Epoch 14/100, Train Loss: 56312.4707\n","Epoch 15/100, Train Loss: 43884.5312\n","Epoch 16/100, Train Loss: 29233.9824\n","Epoch 17/100, Train Loss: 25750.3643\n","Epoch 18/100, Train Loss: 20819.6689\n","Epoch 19/100, Train Loss: 16897.0420\n","Epoch 20/100, Train Loss: 16683.8735\n","Epoch 21/100, Train Loss: 15690.2021\n","Epoch 22/100, Train Loss: 13559.6362\n","Epoch 23/100, Train Loss: 13424.5112\n","Epoch 24/100, Train Loss: 14565.4517\n","Epoch 25/100, Train Loss: 13108.9966\n","Epoch 26/100, Train Loss: 12341.7910\n","Epoch 27/100, Train Loss: 12184.4736\n","Epoch 28/100, Train Loss: 11864.0977\n","Epoch 29/100, Train Loss: 11742.8345\n","Epoch 30/100, Train Loss: 10491.9814\n","Epoch 31/100, Train Loss: 12346.6807\n","Epoch 32/100, Train Loss: 12398.0479\n","Epoch 33/100, Train Loss: 12072.4668\n","Epoch 34/100, Train Loss: 11398.4043\n","Epoch 35/100, Train Loss: 9426.4570\n","Epoch 36/100, Train Loss: 10355.1777\n","Epoch 37/100, Train Loss: 11409.5913\n","Epoch 38/100, Train Loss: 9860.7153\n","Epoch 39/100, Train Loss: 9517.7051\n","Epoch 40/100, Train Loss: 10267.6821\n","Epoch 41/100, Train Loss: 11170.7480\n","Epoch 42/100, Train Loss: 9925.0874\n","Epoch 43/100, Train Loss: 10620.4414\n","Epoch 44/100, Train Loss: 9747.8335\n","Epoch 45/100, Train Loss: 9234.3931\n","Epoch 46/100, Train Loss: 8335.3210\n","Epoch 47/100, Train Loss: 9369.6313\n","Epoch 48/100, Train Loss: 9502.8691\n","Epoch 49/100, Train Loss: 9508.1670\n","Epoch 50/100, Train Loss: 9350.9272\n","Epoch 51/100, Train Loss: 9648.4468\n","Epoch 52/100, Train Loss: 9279.9370\n","Epoch 53/100, Train Loss: 9037.7607\n","Epoch 54/100, Train Loss: 10011.8130\n","Epoch 55/100, Train Loss: 9140.6133\n","Epoch 56/100, Train Loss: 8957.2793\n","Epoch 57/100, Train Loss: 8790.2566\n","Epoch 58/100, Train Loss: 9374.4233\n","Epoch 59/100, Train Loss: 9912.2583\n","Epoch 60/100, Train Loss: 8026.8574\n","Epoch 61/100, Train Loss: 8582.7437\n","Epoch 62/100, Train Loss: 8750.8792\n","Epoch 63/100, Train Loss: 8717.9766\n","Epoch 64/100, Train Loss: 8685.6133\n","Epoch 65/100, Train Loss: 9989.3892\n","Epoch 66/100, Train Loss: 8443.4714\n","Epoch 67/100, Train Loss: 9014.0876\n","Epoch 68/100, Train Loss: 9601.0640\n","Epoch 69/100, Train Loss: 9473.4023\n","Epoch 70/100, Train Loss: 8503.4121\n","Epoch 71/100, Train Loss: 7907.4619\n","Epoch 72/100, Train Loss: 8710.2129\n","Epoch 73/100, Train Loss: 7981.8867\n","Epoch 74/100, Train Loss: 9567.6709\n","Epoch 75/100, Train Loss: 8592.0300\n","Epoch 76/100, Train Loss: 9038.6289\n","Epoch 77/100, Train Loss: 8275.6130\n","Epoch 78/100, Train Loss: 9109.7788\n","Epoch 79/100, Train Loss: 7443.6929\n","Epoch 80/100, Train Loss: 8784.5371\n","Epoch 81/100, Train Loss: 8232.9375\n","Epoch 82/100, Train Loss: 8082.0461\n","Epoch 83/100, Train Loss: 7037.3000\n","Epoch 84/100, Train Loss: 8704.9282\n","Epoch 85/100, Train Loss: 9090.7720\n","Epoch 86/100, Train Loss: 7899.6033\n","Epoch 87/100, Train Loss: 7749.9937\n","Epoch 88/100, Train Loss: 8605.3306\n","Epoch 89/100, Train Loss: 8483.0103\n","Epoch 90/100, Train Loss: 8890.7939\n","Epoch 91/100, Train Loss: 7747.4045\n","Epoch 92/100, Train Loss: 8732.3633\n","Epoch 93/100, Train Loss: 8762.9224\n","Epoch 94/100, Train Loss: 7140.0273\n","Epoch 95/100, Train Loss: 9443.6489\n","Epoch 96/100, Train Loss: 7343.2727\n","Epoch 97/100, Train Loss: 9391.8770\n","Epoch 98/100, Train Loss: 8025.1316\n","Epoch 99/100, Train Loss: 7831.2742\n","Epoch 100/100, Train Loss: 7630.0000\n","Best Validation Loss for 무: 2528.1453\n"]},{"output_type":"stream","name":"stderr","text":["\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:22,  1.05it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:01<00:22,  1.05it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:01<00:21,  1.07it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:02<00:21,  1.07it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:02<00:22,  1.02s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:03<00:22,  1.02s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:03<00:19,  1.07it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:04<00:19,  1.07it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:04<00:16,  1.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:05<00:16,  1.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:05<00:14,  1.30it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:05<00:14,  1.30it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:05<00:13,  1.37it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:06<00:13,  1.37it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:06<00:11,  1.42it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:07<00:11,  1.42it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:07<00:10,  1.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:07<00:10,  1.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:07<00:10,  1.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:08<00:10,  1.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:08<00:09,  1.46it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:09<00:09,  1.46it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:09<00:08,  1.49it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:09<00:08,  1.49it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:09<00:07,  1.52it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:10<00:07,  1.52it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:10<00:07,  1.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:10<00:07,  1.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:10<00:06,  1.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:11<00:06,  1.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:11<00:05,  1.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:12<00:05,  1.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:12<00:05,  1.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:12<00:05,  1.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:12<00:04,  1.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:13<00:04,  1.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:13<00:03,  1.51it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:14<00:03,  1.51it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:14<00:03,  1.31it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:15<00:03,  1.31it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:15<00:03,  1.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:16<00:03,  1.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:16<00:02,  1.15it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:17<00:02,  1.15it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:17<00:01,  1.11it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:18<00:01,  1.11it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:18<00:00,  1.22it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:18<00:00,  1.22it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중: 100%|██████████| 25/25 [00:18<00:00,  1.29it/s, 상태=정상]\u001b[A\n","품목별 전처리 및 모델 학습 -> 상추:  90%|█████████ | 9/10 [01:26<00:11, 11.52s/it]<ipython-input-82-f76e61ff9cd5>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-78-66bf2b439d23>:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 1.1429\n","Epoch 2/100, Train Loss: 0.7945\n","Epoch 3/100, Train Loss: 0.7712\n","Epoch 4/100, Train Loss: 0.7452\n","Epoch 5/100, Train Loss: 0.7544\n","Epoch 6/100, Train Loss: 0.7121\n","Epoch 7/100, Train Loss: 0.7309\n","Epoch 8/100, Train Loss: 0.7293\n","Epoch 9/100, Train Loss: 0.7328\n","Epoch 10/100, Train Loss: 0.6877\n","Epoch 11/100, Train Loss: 0.7067\n","Epoch 12/100, Train Loss: 0.7285\n","Epoch 13/100, Train Loss: 0.6569\n","Epoch 14/100, Train Loss: 0.7042\n","Epoch 15/100, Train Loss: 0.7034\n","Epoch 16/100, Train Loss: 0.6811\n","Epoch 17/100, Train Loss: 0.6796\n","Epoch 18/100, Train Loss: 0.6956\n","Epoch 19/100, Train Loss: 0.7068\n","Epoch 20/100, Train Loss: 0.6888\n","Epoch 21/100, Train Loss: 0.6852\n","Epoch 22/100, Train Loss: 0.6547\n","Epoch 23/100, Train Loss: 0.6853\n","Epoch 24/100, Train Loss: 0.7070\n","Epoch 25/100, Train Loss: 0.6530\n","Epoch 26/100, Train Loss: 0.6691\n","Epoch 27/100, Train Loss: 0.6578\n","Epoch 28/100, Train Loss: 0.6668\n","Epoch 29/100, Train Loss: 0.6465\n","Epoch 30/100, Train Loss: 0.6717\n","Epoch 31/100, Train Loss: 0.6431\n","Epoch 32/100, Train Loss: 0.6902\n","Epoch 33/100, Train Loss: 0.6880\n","Epoch 34/100, Train Loss: 0.6618\n","Epoch 35/100, Train Loss: 0.6724\n","Epoch 36/100, Train Loss: 0.6771\n","Epoch 37/100, Train Loss: 0.6630\n","Epoch 38/100, Train Loss: 0.6245\n","Epoch 39/100, Train Loss: 0.6851\n","Epoch 40/100, Train Loss: 0.6685\n","Epoch 41/100, Train Loss: 0.6218\n","Epoch 42/100, Train Loss: 0.6465\n","Epoch 43/100, Train Loss: 0.6500\n","Epoch 44/100, Train Loss: 0.6686\n","Epoch 45/100, Train Loss: 0.6486\n","Epoch 46/100, Train Loss: 0.6447\n","Epoch 47/100, Train Loss: 0.6718\n","Epoch 48/100, Train Loss: 0.6694\n","Epoch 49/100, Train Loss: 0.6600\n","Epoch 50/100, Train Loss: 0.6547\n","Epoch 51/100, Train Loss: 0.6770\n","Epoch 52/100, Train Loss: 0.6620\n","Epoch 53/100, Train Loss: 0.6464\n","Epoch 54/100, Train Loss: 0.6312\n","Epoch 55/100, Train Loss: 0.6665\n","Epoch 56/100, Train Loss: 0.6491\n","Epoch 57/100, Train Loss: 0.6271\n","Epoch 58/100, Train Loss: 0.6389\n","Epoch 59/100, Train Loss: 0.6563\n","Epoch 60/100, Train Loss: 0.6415\n","Epoch 61/100, Train Loss: 0.6452\n","Epoch 62/100, Train Loss: 0.6794\n","Epoch 63/100, Train Loss: 0.6327\n","Epoch 64/100, Train Loss: 0.6169\n","Epoch 65/100, Train Loss: 0.6591\n","Epoch 66/100, Train Loss: 0.6581\n","Epoch 67/100, Train Loss: 0.6390\n","Epoch 68/100, Train Loss: 0.6284\n","Epoch 69/100, Train Loss: 0.6395\n","Epoch 70/100, Train Loss: 0.6595\n","Epoch 71/100, Train Loss: 0.6181\n","Epoch 72/100, Train Loss: 0.6407\n","Epoch 73/100, Train Loss: 0.6420\n","Epoch 74/100, Train Loss: 0.6427\n","Epoch 75/100, Train Loss: 0.6398\n","Epoch 76/100, Train Loss: 0.6494\n","Epoch 77/100, Train Loss: 0.6240\n","Epoch 78/100, Train Loss: 0.6220\n","Epoch 79/100, Train Loss: 0.6325\n","Epoch 80/100, Train Loss: 0.6557\n","Epoch 81/100, Train Loss: 0.6343\n","Epoch 82/100, Train Loss: 0.6451\n","Epoch 83/100, Train Loss: 0.6076\n","Epoch 84/100, Train Loss: 0.6411\n","Epoch 85/100, Train Loss: 0.6024\n","Epoch 86/100, Train Loss: 0.6406\n","Epoch 87/100, Train Loss: 0.6305\n","Epoch 88/100, Train Loss: 0.6229\n","Epoch 89/100, Train Loss: 0.6587\n","Epoch 90/100, Train Loss: 0.6504\n","Epoch 91/100, Train Loss: 0.6455\n","Epoch 92/100, Train Loss: 0.6705\n","Epoch 93/100, Train Loss: 0.6350\n","Epoch 94/100, Train Loss: 0.6471\n","Epoch 95/100, Train Loss: 0.6442\n","Epoch 96/100, Train Loss: 0.6659\n","Epoch 97/100, Train Loss: 0.6414\n","Epoch 98/100, Train Loss: 0.6470\n","Epoch 99/100, Train Loss: 0.6586\n","Epoch 100/100, Train Loss: 0.6520\n","Best Validation Loss for 상추: 0.5871\n"]},{"output_type":"stream","name":"stderr","text":["\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:05,  4.35it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:05,  4.35it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:00<00:05,  4.34it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:00<00:05,  4.34it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:00<00:04,  4.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:00<00:04,  4.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:00<00:04,  4.76it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:01<00:04,  4.76it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:01<00:04,  4.84it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:01<00:04,  4.84it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:01<00:04,  4.69it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:01<00:04,  4.69it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:01<00:04,  4.41it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:01<00:04,  4.41it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:01<00:03,  4.52it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:01<00:03,  4.52it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:01<00:03,  4.60it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:02<00:03,  4.60it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:02<00:03,  4.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:02<00:03,  4.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:02<00:03,  4.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:02<00:03,  4.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:02<00:02,  4.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:02<00:02,  4.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:02<00:02,  4.58it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:03<00:02,  4.58it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:03<00:02,  4.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:03<00:02,  4.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:03<00:02,  4.47it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:03<00:02,  4.47it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:03<00:02,  4.36it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:03<00:02,  4.36it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:03<00:01,  4.41it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:03<00:01,  4.41it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:03<00:01,  4.53it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:04<00:01,  4.53it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:04<00:01,  4.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:04<00:01,  4.59it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:04<00:01,  4.62it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:04<00:01,  4.62it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:04<00:00,  4.51it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:04<00:00,  4.51it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:04<00:00,  4.38it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:05<00:00,  4.38it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:05<00:00,  3.91it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:05<00:00,  3.91it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:05<00:00,  3.50it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:05<00:00,  3.50it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중: 100%|██████████| 25/25 [00:05<00:00,  3.51it/s, 상태=정상]\u001b[A\n","품목별 전처리 및 모델 학습 -> 배추: : 11it [01:35, 11.06s/it]                      <ipython-input-82-f76e61ff9cd5>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-78-66bf2b439d23>:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 1.0697\n","Epoch 2/100, Train Loss: 0.7844\n","Epoch 3/100, Train Loss: 0.7118\n","Epoch 4/100, Train Loss: 0.6988\n","Epoch 5/100, Train Loss: 0.7163\n","Epoch 6/100, Train Loss: 0.6240\n","Epoch 7/100, Train Loss: 0.6963\n","Epoch 8/100, Train Loss: 0.7304\n","Epoch 9/100, Train Loss: 0.6437\n","Epoch 10/100, Train Loss: 0.6604\n","Epoch 11/100, Train Loss: 0.5947\n","Epoch 12/100, Train Loss: 0.6501\n","Epoch 13/100, Train Loss: 0.5983\n","Epoch 14/100, Train Loss: 0.6317\n","Epoch 15/100, Train Loss: 0.6299\n","Epoch 16/100, Train Loss: 0.6238\n","Epoch 17/100, Train Loss: 0.6258\n","Epoch 18/100, Train Loss: 0.5984\n","Epoch 19/100, Train Loss: 0.6171\n","Epoch 20/100, Train Loss: 0.6079\n","Epoch 21/100, Train Loss: 0.5685\n","Epoch 22/100, Train Loss: 0.5659\n","Epoch 23/100, Train Loss: 0.6068\n","Epoch 24/100, Train Loss: 0.6293\n","Epoch 25/100, Train Loss: 0.5708\n","Epoch 26/100, Train Loss: 0.5594\n","Epoch 27/100, Train Loss: 0.5908\n","Epoch 28/100, Train Loss: 0.5457\n","Epoch 29/100, Train Loss: 0.6132\n","Epoch 30/100, Train Loss: 0.5900\n","Epoch 31/100, Train Loss: 0.5401\n","Epoch 32/100, Train Loss: 0.5668\n","Epoch 33/100, Train Loss: 0.6040\n","Epoch 34/100, Train Loss: 0.5727\n","Epoch 35/100, Train Loss: 0.5641\n","Epoch 36/100, Train Loss: 0.5881\n","Epoch 37/100, Train Loss: 0.5591\n","Epoch 38/100, Train Loss: 0.5453\n","Epoch 39/100, Train Loss: 0.5523\n","Epoch 40/100, Train Loss: 0.5803\n","Epoch 41/100, Train Loss: 0.5935\n","Epoch 42/100, Train Loss: 0.5633\n","Epoch 43/100, Train Loss: 0.6219\n","Epoch 44/100, Train Loss: 0.5414\n","Epoch 45/100, Train Loss: 0.5566\n","Epoch 46/100, Train Loss: 0.5520\n","Epoch 47/100, Train Loss: 0.5739\n","Epoch 48/100, Train Loss: 0.5686\n","Epoch 49/100, Train Loss: 0.5984\n","Epoch 50/100, Train Loss: 0.5273\n","Epoch 51/100, Train Loss: 0.5597\n","Epoch 52/100, Train Loss: 0.6031\n","Epoch 53/100, Train Loss: 0.5253\n","Epoch 54/100, Train Loss: 0.5880\n","Epoch 55/100, Train Loss: 0.5349\n","Epoch 56/100, Train Loss: 0.5819\n","Epoch 57/100, Train Loss: 0.4931\n","Epoch 58/100, Train Loss: 0.5438\n","Epoch 59/100, Train Loss: 0.5613\n","Epoch 60/100, Train Loss: 0.5357\n","Epoch 61/100, Train Loss: 0.5360\n","Epoch 62/100, Train Loss: 0.5569\n","Epoch 63/100, Train Loss: 0.5530\n","Epoch 64/100, Train Loss: 0.5509\n","Epoch 65/100, Train Loss: 0.5225\n","Epoch 66/100, Train Loss: 0.6011\n","Epoch 67/100, Train Loss: 0.5629\n","Epoch 68/100, Train Loss: 0.5572\n","Epoch 69/100, Train Loss: 0.5807\n","Epoch 70/100, Train Loss: 0.5250\n","Epoch 71/100, Train Loss: 0.5578\n","Epoch 72/100, Train Loss: 0.5756\n","Epoch 73/100, Train Loss: 0.5524\n","Epoch 74/100, Train Loss: 0.5737\n","Epoch 75/100, Train Loss: 0.5551\n","Epoch 76/100, Train Loss: 0.5670\n","Epoch 77/100, Train Loss: 0.5722\n","Epoch 78/100, Train Loss: 0.5377\n","Epoch 79/100, Train Loss: 0.5599\n","Epoch 80/100, Train Loss: 0.6019\n","Epoch 81/100, Train Loss: 0.5355\n","Epoch 82/100, Train Loss: 0.5460\n","Epoch 83/100, Train Loss: 0.5645\n","Epoch 84/100, Train Loss: 0.5358\n","Epoch 85/100, Train Loss: 0.5352\n","Epoch 86/100, Train Loss: 0.5743\n","Epoch 87/100, Train Loss: 0.5705\n","Epoch 88/100, Train Loss: 0.5692\n","Epoch 89/100, Train Loss: 0.5217\n","Epoch 90/100, Train Loss: 0.5335\n","Epoch 91/100, Train Loss: 0.5470\n","Epoch 92/100, Train Loss: 0.5148\n","Epoch 93/100, Train Loss: 0.5674\n","Epoch 94/100, Train Loss: 0.5513\n","Epoch 95/100, Train Loss: 0.5784\n","Epoch 96/100, Train Loss: 0.5603\n","Epoch 97/100, Train Loss: 0.5833\n","Epoch 98/100, Train Loss: 0.5306\n","Epoch 99/100, Train Loss: 0.5235\n","Epoch 100/100, Train Loss: 0.5419\n","Best Validation Loss for 배추: 0.4928\n"]},{"output_type":"stream","name":"stderr","text":["\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:10,  2.26it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:10,  2.26it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:00<00:10,  2.19it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:01<00:10,  2.19it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:01<00:10,  2.14it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:01<00:10,  2.14it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:01<00:09,  2.10it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:02<00:09,  2.10it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:02<00:09,  2.12it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:02<00:09,  2.12it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:02<00:08,  2.13it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:03<00:08,  2.13it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:03<00:08,  2.16it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:03<00:08,  2.16it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:03<00:07,  2.19it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:04<00:07,  2.19it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:04<00:07,  2.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:04<00:07,  2.20it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:04<00:06,  2.18it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:05<00:06,  2.18it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:05<00:06,  2.17it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:05<00:06,  2.17it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:05<00:05,  2.19it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:05<00:05,  2.19it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:06<00:05,  2.17it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:06<00:05,  2.17it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:06<00:05,  1.85it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:07<00:05,  1.85it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:07<00:05,  1.94it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:07<00:05,  1.94it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:07<00:04,  1.83it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:08<00:04,  1.83it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:08<00:04,  1.75it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:09<00:04,  1.75it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:09<00:04,  1.61it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:09<00:04,  1.61it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:09<00:03,  1.61it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:10<00:03,  1.61it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:10<00:03,  1.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:11<00:03,  1.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:11<00:02,  1.50it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:11<00:02,  1.50it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:11<00:02,  1.49it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:12<00:02,  1.49it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:12<00:01,  1.65it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:12<00:01,  1.65it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:12<00:00,  1.80it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:13<00:00,  1.80it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중: 100%|██████████| 25/25 [00:13<00:00,  1.89it/s, 상태=정상]\u001b[A\n","품목별 전처리 및 모델 학습 -> 양파: : 12it [01:55, 10.45s/it]<ipython-input-82-f76e61ff9cd5>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-78-66bf2b439d23>:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 0.9080\n","Epoch 2/100, Train Loss: 0.5174\n","Epoch 3/100, Train Loss: 0.4138\n","Epoch 4/100, Train Loss: 0.4208\n","Epoch 5/100, Train Loss: 0.4949\n","Epoch 6/100, Train Loss: 0.4014\n","Epoch 7/100, Train Loss: 0.3976\n","Epoch 8/100, Train Loss: 0.4199\n","Epoch 9/100, Train Loss: 0.4057\n","Epoch 10/100, Train Loss: 0.4205\n","Epoch 11/100, Train Loss: 0.4322\n","Epoch 12/100, Train Loss: 0.3986\n","Epoch 13/100, Train Loss: 0.3691\n","Epoch 14/100, Train Loss: 0.3787\n","Epoch 15/100, Train Loss: 0.3940\n","Epoch 16/100, Train Loss: 0.3806\n","Epoch 17/100, Train Loss: 0.3890\n","Epoch 18/100, Train Loss: 0.3918\n","Epoch 19/100, Train Loss: 0.3575\n","Epoch 20/100, Train Loss: 0.3853\n","Epoch 21/100, Train Loss: 0.3789\n","Epoch 22/100, Train Loss: 0.3562\n","Epoch 23/100, Train Loss: 0.3779\n","Epoch 24/100, Train Loss: 0.3356\n","Epoch 25/100, Train Loss: 0.3517\n","Epoch 26/100, Train Loss: 0.3738\n","Epoch 27/100, Train Loss: 0.3545\n","Epoch 28/100, Train Loss: 0.3713\n","Epoch 29/100, Train Loss: 0.3545\n","Epoch 30/100, Train Loss: 0.3346\n","Epoch 31/100, Train Loss: 0.3385\n","Epoch 32/100, Train Loss: 0.3321\n","Epoch 33/100, Train Loss: 0.3545\n","Epoch 34/100, Train Loss: 0.3189\n","Epoch 35/100, Train Loss: 0.3484\n","Epoch 36/100, Train Loss: 0.3789\n","Epoch 37/100, Train Loss: 0.3342\n","Epoch 38/100, Train Loss: 0.3335\n","Epoch 39/100, Train Loss: 0.3145\n","Epoch 40/100, Train Loss: 0.3558\n","Epoch 41/100, Train Loss: 0.3190\n","Epoch 42/100, Train Loss: 0.3625\n","Epoch 43/100, Train Loss: 0.3190\n","Epoch 44/100, Train Loss: 0.3316\n","Epoch 45/100, Train Loss: 0.3149\n","Epoch 46/100, Train Loss: 0.3491\n","Epoch 47/100, Train Loss: 0.3066\n","Epoch 48/100, Train Loss: 0.3304\n","Epoch 49/100, Train Loss: 0.3180\n","Epoch 50/100, Train Loss: 0.3296\n","Epoch 51/100, Train Loss: 0.3544\n","Epoch 52/100, Train Loss: 0.3094\n","Epoch 53/100, Train Loss: 0.3407\n","Epoch 54/100, Train Loss: 0.3018\n","Epoch 55/100, Train Loss: 0.3217\n","Epoch 56/100, Train Loss: 0.2983\n","Epoch 57/100, Train Loss: 0.3181\n","Epoch 58/100, Train Loss: 0.3304\n","Epoch 59/100, Train Loss: 0.3169\n","Epoch 60/100, Train Loss: 0.3023\n","Epoch 61/100, Train Loss: 0.3077\n","Epoch 62/100, Train Loss: 0.3292\n","Epoch 63/100, Train Loss: 0.3121\n","Epoch 64/100, Train Loss: 0.3148\n","Epoch 65/100, Train Loss: 0.3306\n","Epoch 66/100, Train Loss: 0.2952\n","Epoch 67/100, Train Loss: 0.3102\n","Epoch 68/100, Train Loss: 0.3228\n","Epoch 69/100, Train Loss: 0.3227\n","Epoch 70/100, Train Loss: 0.3262\n","Epoch 71/100, Train Loss: 0.3041\n","Epoch 72/100, Train Loss: 0.2933\n","Epoch 73/100, Train Loss: 0.3096\n","Epoch 74/100, Train Loss: 0.2714\n","Epoch 75/100, Train Loss: 0.3113\n","Epoch 76/100, Train Loss: 0.3089\n","Epoch 77/100, Train Loss: 0.3098\n","Epoch 78/100, Train Loss: 0.2856\n","Epoch 79/100, Train Loss: 0.3217\n","Epoch 80/100, Train Loss: 0.3064\n","Epoch 81/100, Train Loss: 0.3246\n","Epoch 82/100, Train Loss: 0.3136\n","Epoch 83/100, Train Loss: 0.3166\n","Epoch 84/100, Train Loss: 0.3346\n","Epoch 85/100, Train Loss: 0.3119\n","Epoch 86/100, Train Loss: 0.3251\n","Epoch 87/100, Train Loss: 0.2998\n","Epoch 88/100, Train Loss: 0.2956\n","Epoch 89/100, Train Loss: 0.2944\n","Epoch 90/100, Train Loss: 0.3028\n","Epoch 91/100, Train Loss: 0.3340\n","Epoch 92/100, Train Loss: 0.2955\n","Epoch 93/100, Train Loss: 0.2773\n","Epoch 94/100, Train Loss: 0.2813\n","Epoch 95/100, Train Loss: 0.2969\n","Epoch 96/100, Train Loss: 0.3072\n","Epoch 97/100, Train Loss: 0.3080\n","Epoch 98/100, Train Loss: 0.3260\n","Epoch 99/100, Train Loss: 0.3350\n","Epoch 100/100, Train Loss: 0.2998\n","Best Validation Loss for 양파: 0.1941\n"]},{"output_type":"stream","name":"stderr","text":["\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n","테스트 파일 추론 중:   0%|          | 0/25 [00:01<?, ?it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:01<00:29,  1.21s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:02<00:29,  1.21s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:02<00:27,  1.21s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:03<00:27,  1.21s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:03<00:27,  1.26s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:04<00:27,  1.26s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:05<00:26,  1.26s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:06<00:26,  1.26s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:06<00:25,  1.25s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:07<00:25,  1.25s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:07<00:26,  1.37s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:09<00:26,  1.37s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:09<00:23,  1.32s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:10<00:23,  1.32s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:10<00:24,  1.45s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:12<00:24,  1.45s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:12<00:24,  1.56s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:14<00:24,  1.56s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:14<00:23,  1.56s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:15<00:23,  1.56s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:15<00:20,  1.49s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:16<00:20,  1.49s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:16<00:18,  1.41s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:17<00:18,  1.41s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:17<00:16,  1.37s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:19<00:16,  1.37s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:19<00:15,  1.44s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:20<00:15,  1.44s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:20<00:13,  1.36s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:21<00:13,  1.36s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:21<00:11,  1.31s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:23<00:11,  1.31s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:23<00:10,  1.28s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:24<00:10,  1.28s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:24<00:09,  1.42s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:26<00:09,  1.42s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:26<00:09,  1.52s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:28<00:09,  1.52s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:28<00:07,  1.54s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:29<00:07,  1.54s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:29<00:05,  1.45s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:30<00:05,  1.45s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:30<00:04,  1.40s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:32<00:04,  1.40s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:32<00:02,  1.44s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:33<00:02,  1.44s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:33<00:01,  1.38s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:34<00:01,  1.38s/it, 상태=정상]\u001b[A\n","테스트 파일 추론 중: 100%|██████████| 25/25 [00:34<00:00,  1.36s/it, 상태=정상]\u001b[A\n","품목별 전처리 및 모델 학습 -> 대파: : 13it [02:43, 19.10s/it]<ipython-input-82-f76e61ff9cd5>:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n","<ipython-input-78-66bf2b439d23>:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():  # GPU에서 Mixed Precision Training\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100, Train Loss: 1.4530\n","Epoch 2/100, Train Loss: 1.0267\n","Epoch 3/100, Train Loss: 0.7770\n","Epoch 4/100, Train Loss: 0.6380\n","Epoch 5/100, Train Loss: 0.5984\n","Epoch 6/100, Train Loss: 0.5414\n","Epoch 7/100, Train Loss: 0.5437\n","Epoch 8/100, Train Loss: 0.5049\n","Epoch 9/100, Train Loss: 0.5058\n","Epoch 10/100, Train Loss: 0.4830\n","Epoch 11/100, Train Loss: 0.4676\n","Epoch 12/100, Train Loss: 0.4643\n","Epoch 13/100, Train Loss: 0.4689\n","Epoch 14/100, Train Loss: 0.5203\n","Epoch 15/100, Train Loss: 0.4828\n","Epoch 16/100, Train Loss: 0.4847\n","Epoch 17/100, Train Loss: 0.4848\n","Epoch 18/100, Train Loss: 0.4662\n","Epoch 19/100, Train Loss: 0.4560\n","Epoch 20/100, Train Loss: 0.4343\n","Epoch 21/100, Train Loss: 0.4972\n","Epoch 22/100, Train Loss: 0.4787\n","Epoch 23/100, Train Loss: 0.4505\n","Epoch 24/100, Train Loss: 0.4343\n","Epoch 25/100, Train Loss: 0.4853\n","Epoch 26/100, Train Loss: 0.4433\n","Epoch 27/100, Train Loss: 0.4321\n","Epoch 28/100, Train Loss: 0.4028\n","Epoch 29/100, Train Loss: 0.4483\n","Epoch 30/100, Train Loss: 0.3888\n","Epoch 31/100, Train Loss: 0.4502\n","Epoch 32/100, Train Loss: 0.4497\n","Epoch 33/100, Train Loss: 0.5014\n","Epoch 34/100, Train Loss: 0.4424\n","Epoch 35/100, Train Loss: 0.4098\n","Epoch 36/100, Train Loss: 0.4317\n","Epoch 37/100, Train Loss: 0.4165\n","Epoch 38/100, Train Loss: 0.4197\n","Epoch 39/100, Train Loss: 0.4468\n","Epoch 40/100, Train Loss: 0.4174\n","Epoch 41/100, Train Loss: 0.4334\n","Epoch 42/100, Train Loss: 0.4234\n","Epoch 43/100, Train Loss: 0.4043\n","Epoch 44/100, Train Loss: 0.3690\n","Epoch 45/100, Train Loss: 0.4349\n","Epoch 46/100, Train Loss: 0.4319\n","Epoch 47/100, Train Loss: 0.4118\n","Epoch 48/100, Train Loss: 0.4093\n","Epoch 49/100, Train Loss: 0.3917\n","Epoch 50/100, Train Loss: 0.4030\n","Epoch 51/100, Train Loss: 0.3696\n","Epoch 52/100, Train Loss: 0.4179\n","Epoch 53/100, Train Loss: 0.3855\n","Epoch 54/100, Train Loss: 0.4233\n","Epoch 55/100, Train Loss: 0.4197\n","Epoch 56/100, Train Loss: 0.3945\n","Epoch 57/100, Train Loss: 0.3833\n","Epoch 58/100, Train Loss: 0.4050\n","Epoch 59/100, Train Loss: 0.4243\n","Epoch 60/100, Train Loss: 0.4493\n","Epoch 61/100, Train Loss: 0.4041\n","Epoch 62/100, Train Loss: 0.4091\n","Epoch 63/100, Train Loss: 0.3832\n","Epoch 64/100, Train Loss: 0.4203\n","Epoch 65/100, Train Loss: 0.3761\n","Epoch 66/100, Train Loss: 0.4000\n","Epoch 67/100, Train Loss: 0.4169\n","Epoch 68/100, Train Loss: 0.3901\n","Epoch 69/100, Train Loss: 0.3975\n","Epoch 70/100, Train Loss: 0.4012\n","Epoch 71/100, Train Loss: 0.4002\n","Epoch 72/100, Train Loss: 0.4020\n","Epoch 73/100, Train Loss: 0.3938\n","Epoch 74/100, Train Loss: 0.3942\n","Epoch 75/100, Train Loss: 0.3694\n","Epoch 76/100, Train Loss: 0.3740\n","Epoch 77/100, Train Loss: 0.3878\n","Epoch 78/100, Train Loss: 0.4018\n","Epoch 79/100, Train Loss: 0.3590\n","Epoch 80/100, Train Loss: 0.4168\n","Epoch 81/100, Train Loss: 0.3521\n","Epoch 82/100, Train Loss: 0.3991\n","Epoch 83/100, Train Loss: 0.3914\n","Epoch 84/100, Train Loss: 0.3686\n","Epoch 85/100, Train Loss: 0.4107\n","Epoch 86/100, Train Loss: 0.4161\n","Epoch 87/100, Train Loss: 0.4099\n","Epoch 88/100, Train Loss: 0.3842\n","Epoch 89/100, Train Loss: 0.4162\n","Epoch 90/100, Train Loss: 0.3851\n","Epoch 91/100, Train Loss: 0.3893\n","Epoch 92/100, Train Loss: 0.4025\n","Epoch 93/100, Train Loss: 0.3977\n","Epoch 94/100, Train Loss: 0.3835\n","Epoch 95/100, Train Loss: 0.4130\n","Epoch 96/100, Train Loss: 0.4084\n","Epoch 97/100, Train Loss: 0.4109\n","Epoch 98/100, Train Loss: 0.3858\n","Epoch 99/100, Train Loss: 0.4138\n","Epoch 100/100, Train Loss: 0.3964\n","Best Validation Loss for 대파: 0.3664\n"]},{"output_type":"stream","name":"stderr","text":["\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n","테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:00<00:13,  1.73it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   4%|▍         | 1/25 [00:01<00:13,  1.73it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:01<00:13,  1.70it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:   8%|▊         | 2/25 [00:01<00:13,  1.70it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:01<00:12,  1.77it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  12%|█▏        | 3/25 [00:02<00:12,  1.77it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:02<00:10,  2.02it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  16%|█▌        | 4/25 [00:02<00:10,  2.02it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:02<00:09,  2.18it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  20%|██        | 5/25 [00:02<00:09,  2.18it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:02<00:08,  2.32it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  24%|██▍       | 6/25 [00:03<00:08,  2.32it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:03<00:07,  2.39it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  28%|██▊       | 7/25 [00:03<00:07,  2.39it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:03<00:06,  2.43it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  32%|███▏      | 8/25 [00:04<00:06,  2.43it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:04<00:06,  2.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  36%|███▌      | 9/25 [00:04<00:06,  2.48it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:04<00:06,  2.49it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  40%|████      | 10/25 [00:04<00:06,  2.49it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:04<00:05,  2.51it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  44%|████▍     | 11/25 [00:05<00:05,  2.51it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:05<00:05,  2.44it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  48%|████▊     | 12/25 [00:05<00:05,  2.44it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:05<00:04,  2.50it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  52%|█████▏    | 13/25 [00:06<00:04,  2.50it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:06<00:04,  2.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  56%|█████▌    | 14/25 [00:06<00:04,  2.54it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:06<00:03,  2.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  60%|██████    | 15/25 [00:06<00:03,  2.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:06<00:03,  2.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  64%|██████▍   | 16/25 [00:07<00:03,  2.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:07<00:03,  2.58it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  68%|██████▊   | 17/25 [00:07<00:03,  2.58it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:07<00:02,  2.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  72%|███████▏  | 18/25 [00:07<00:02,  2.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:07<00:02,  2.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  76%|███████▌  | 19/25 [00:08<00:02,  2.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:08<00:01,  2.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  80%|████████  | 20/25 [00:08<00:01,  2.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:08<00:01,  2.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  84%|████████▍ | 21/25 [00:09<00:01,  2.55it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:09<00:01,  2.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  88%|████████▊ | 22/25 [00:09<00:01,  2.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:09<00:00,  2.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  92%|█████████▏| 23/25 [00:09<00:00,  2.57it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:09<00:00,  2.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중:  96%|█████████▌| 24/25 [00:10<00:00,  2.56it/s, 상태=정상]\u001b[A\n","테스트 파일 추론 중: 100%|██████████| 25/25 [00:10<00:00,  2.61it/s, 상태=정상]\u001b[A\n","품목별 전처리 및 모델 학습 -> 대파: 100%|██████████| 10/10 [02:58<00:00, 17.84s/it]\n"]}],"source":["from torch.cuda.amp import GradScaler\n","from torch.cuda.amp import autocast\n","\n","\n","품목별_predictions = {}\n","품목별_scalers = {}\n","\n","pbar_outer = tqdm(item_list, desc=\"품목 처리 중\", position=0)\n","for 품목명 in pbar_outer:\n","    pbar_outer.set_description(f\"품목별 전처리 및 모델 학습 -> {품목명}\")\n","    train_data, scaler = process_data(\"./train/train.csv\",\n","                              \"./train/meta/TRAIN_산지공판장_2018-2021.csv\",\n","                              \"./train/meta/TRAIN_전국도매_2018-2021.csv\",\n","                              품목명)\n","    품목별_scalers[품목명] = scaler\n","    dataset = AgriculturePriceDataset(train_data)\n","\n","    # 데이터를 train과 validation으로 분할\n","    train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n","\n","    train_loader = DataLoader(train_data, CFG.batch_size, shuffle=True)\n","    val_loader = DataLoader(val_data, CFG.batch_size, shuffle=False)\n","\n","    input_size = len(dataset.numeric_columns)\n","\n","    model = TimeSeriesTransformer(\n","            input_size=input_size,\n","            hidden_size=CFG.hidden_size,\n","            num_layers=CFG.num_layers,\n","            num_heads=CFG.num_heads,\n","            output_size=CFG.output_size,\n","            dropout=CFG.dropout\n","        ).to(device)\n","    criterion = NMAELoss()\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n","\n","    best_val_loss = float('inf')\n","    os.makedirs('models', exist_ok=True)\n","\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=CFG.step_size, gamma=CFG.gamma)\n","    scaler = GradScaler()\n","\n","    for epoch in range(CFG.epoch):\n","        train_loss = train_model(\n","            model, train_loader, criterion, optimizer, scheduler, scaler, device\n","        )\n","        val_loss = evaluate_model(model, val_loader, criterion, device)\n","        # Gradient clipping\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            torch.save(model.state_dict(), f'models/best_model_{품목명}.pth')\n","\n","        print(f'Epoch {epoch+1}/{CFG.epoch}, Train Loss: {train_loss:.4f}')\n","    print(f'Best Validation Loss for {품목명}: {best_val_loss:.4f}')\n","\n","    품목_predictions = []\n","\n","    ### 추론\n","    pbar_inner = tqdm(range(25), desc=\"테스트 파일 추론 중\", position=1, leave=False)\n","    for i in pbar_inner:\n","        test_file = f\"./test/TEST_{i:02d}.csv\"\n","        산지공판장_file = f\"./test/meta/TEST_산지공판장_{i:02d}.csv\"\n","        전국도매_file = f\"./test/meta/TEST_전국도매_{i:02d}.csv\"\n","\n","        test_data, _ = process_data(test_file, 산지공판장_file, 전국도매_file, 품목명, scaler=품목별_scalers[품목명])\n","        test_dataset = AgriculturePriceDataset(test_data, is_test=True)\n","        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n","\n","        model.eval()\n","        predictions = []\n","        with torch.no_grad():\n","            for batch in test_loader:\n","                batch = batch.to(device)  # 입력 데이터를 GPU로 이동\n","                output = model(batch)    # 모델과 데이터가 GPU에서 처리\n","                predictions.append(output.cpu().numpy())\n","\n","        predictions_array = np.concatenate(predictions)\n","\n","        # 예측값을 원래 스케일로 복원\n","        price_column_index = test_data.columns.get_loc(test_dataset.price_column)\n","        predictions_reshaped = predictions_array.reshape(-1, 1)\n","\n","        # 가격 열에 대해서만 inverse_transform 적용\n","        price_scaler = MinMaxScaler()\n","        price_scaler.min_ = 품목별_scalers[품목명].min_[price_column_index]\n","        price_scaler.scale_ = 품목별_scalers[품목명].scale_[price_column_index]\n","        predictions_original_scale = price_scaler.inverse_transform(predictions_reshaped)\n","        #print(predictions_original_scale)\n","\n","        if np.isnan(predictions_original_scale).any():\n","            pbar_inner.set_postfix({\"상태\": \"NaN\"})\n","        else:\n","            pbar_inner.set_postfix({\"상태\": \"정상\"})\n","            품목_predictions.extend(predictions_original_scale.flatten())\n","\n","\n","    품목별_predictions[품목명] = 품목_predictions\n","    pbar_outer.update(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3uuyi349gmC"},"outputs":[],"source":["sample_submission = pd.read_csv('./sample_submission.csv')\n","\n","for 품목명, predictions in 품목별_predictions.items():\n","    sample_submission[품목명] = predictions\n","\n","# 결과 저장\n","sample_submission.to_csv('./baseline_submission22.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyM0pK+ZcB+JdBF4cSPL6KWK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}